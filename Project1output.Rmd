<center>
# Project 1
Name: Ian Resor  
Partner: Queen Caoile  
04/03/2023  
</center>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Contents
\setlength{leftskip}{2cm}
Background .............................................1  
Data .......................................................1  
Project Objectives .....................................1  
  \setlength{leftskip}{4cm}
  Objective 1 ..............................................1  
  Objective 2 ..............................................1  
  Objective 3 ..............................................1  
  Objective 4 ..............................................1  
  GitHub Log ..............................................1  
\setlength{leftskip}{0pt}


## Background
The World Health Organization has recently employed a new data science initiative, *CSIT-165*, that uses data science to characterize pandemic diseases. 
*CSIT-165* disseminates data driven analyses to global decision makers.

*CSIT-165* is a conglomerate comprised of two fabricated entities: *Global Health Union (GHU)* and *Private Diagnostic Laboratories (PDL)*. 
The contents of this document contains the analysis of a team of data scientists from one of these two entities.

## Data
We will be analyzing 2 data sets for 2019 Novel Coronavirus operated by the John Hopkins University Center for Systems Science and Engineering (JHU CSSE).Data includes daily time series CSV summary tables, including confirmations, recoveries, and deaths. Country/region are countries/regions that conform to World Health Organization (WHO). Lat and Long refer to coordinates references for the user. Date fiends are stored in MM/DD/YYYY format.  
We will be using the data sets relating to confirmations and deaths

```{r}
#read in raw csvs into data frames. These files are created by using the wget command in terminal with links to original data set from John Hopkins.
library(readr)
confirmed_global <- read.csv("https://raw.githubusercontent.com/Nomad713/Project1/main/time_series_covid19_confirmed_global.csv")
deaths_global <- read.csv("https://raw.githubusercontent.com/Nomad713/Project1/main/time_series_covid19_deaths_global.csv")
```

## Project Objectives
### Objective 1 - Determine where COVID-19 originated from
```{r ob1}

find_origin = function(df1, df2){
  #iterate through the first data frame and find the greatest number of confirmed cases on the first recorded day in the data set
  for(i in 1:ncol(df1)){
    if(df1[i,5] %in% max(df1[, 5])){
      origin_confirmed <- c(df1[i,1])
    }
  }
  print(paste(origin_confirmed, "has the greatest number of confirmed cases on the first recorded day in the data set."))
  
  #iterate through the second data frame and find the greatest number of deaths on the first recorded day in the data set
  for (i in 1:ncol(df2)){
    if(df2[i,5] %in% max(df2[, 5])){
      origin_death <- c(df2[i,1])
    }
  }
  print(paste(origin_death, "has the greatest number of confirmed deaths on the first recorded day in the data set."))
  #If the greatest number of confirmations and deaths on the first recorded day in the data set are the same, that is the origin of COVID-19
  if(origin_confirmed==origin_death){
    origin=origin_confirmed
    print(paste(origin, "is predicted to be where COVID-19 originated from."))
  }
}

find_origin(confirmed_global, deaths_global)
```

### Objective 2 - Where is the most recent area to have a first confirmed case?
```{r ob2}
#create a subset of confirmed_global that only contains date information
dates <- confirmed_global[, 5:ncol(confirmed_global)]

# find the date of the first confirmed case for each country
first_case_dates <- apply(dates, 1, function(x) {
  # find the index of the first element in each row that is greater than 0
  first_case_index <- which(x > 0)[1]
  # if there is a first case index, return the corresponding column name
  if (!is.na(first_case_index)) {
    colnames(dates)[first_case_index]
  } else {
    # if there is no first case index, return NA
    NA
  }
})

# format text dates to be date data types
first_case_dates <- as.Date(first_case_dates, format = "X%m.%d.%y")

# create a new data frame with the first case dates for each areas
area <- confirmed_global[, 1:4]
area$first_case <- first_case_dates

# filter out areas with no confirmed cases
area <- area[!is.na(area$first_case),]

# sort the first cases by date in descending order
area <- area[order(area$first_case, decreasing = TRUE),]

# most recent area to have a first confirmed case will be first
recent_area <- paste (area[1,1],area[1,2])
recent_date <- format(area[1,5], "%m/%d/%Y")
recent_long <- area[1,4]
recent_lat <- area[1,3]

# print the most recent area to have a first confirmed case
cat("The most recent area to have a first confirmed case is", recent_area,  "on", recent_date)
```

### Objective 3 - How far away is the most recent area to have a first confirmed case from where the first confirmed cases occurred? 
```{r ob3}
# Find the earliest date
earliest_date <- min(area$first_case)
# Subset the data frame to include only rows with the earliest date
first_case_location <- subset(area, first_case == earliest_date)

# Create a new data frame to store the distances
distances_df <- data.frame(location = character(),
                            distance_miles = numeric(),
                            stringsAsFactors = FALSE)

# Loop over each row in first_case_location data frame
for (i in 1:nrow(first_case_location)) {
  # Get the location and its coordinates
  location <- paste(first_case_location[i, 1], first_case_location[i, 2], sep = ", ")
  lat <- first_case_location[i, 3]
  lon <- first_case_location[i, 4]
  
  # Calculate the distance in meters using distm function
  distance_m <- geosphere::distm(c(recent_long, recent_lat), c(lon, lat))
  
  # Convert distance from meters to miles
  distance_miles <- distance_m / 1609.344
  
  # Add the location and distance to the distances_df data frame
  distances_df <- rbind(distances_df, data.frame(location = location, distance_miles = distance_miles, stringsAsFactors = FALSE))
}

# Print the table of distances
print(distances_df)

# Print required statements
for (i in 1:nrow(distances_df)){
  cat(recent_area,"is", distances_df[i,2], " miles away from", distances_df[i,1],"\n")
}
```

<<<<<<< HEAD
### Objective 4 - Risk Scores
### Objective 5 - Top 5 countries with the most COVID-19 related confirmations and deaths
```{r ob5}
# grab the largest number of confirmed COVID-19 confirmed cases
largest_numbers <- apply(dates,1,max)

# create a new data frame with the first case dates for each areas
dates$max<-largest_numbers
print(dates)

# create a new data frame with the first case dates for each areas
confirmed_country <- confirmed_global[, 2]
confirmed_country$max <- largest_numbers
print(confirmed_country)
# Group by country and summarize confirmed cases

```
=======

### Objective 4 - Risk Scores 
```{r}
library(tidyverse)
#filter out NA from Lat as well as where Lat = 0
confirmed <- subset(confirmed_global[!is.na(confirmed_global$Lat)], Lat != 0)
deaths <- subset(deaths_global[!is.na(deaths_global$Lat)], Lat !=0)


#creating vectors with the last recorded values in time which are most up to date
recent_confirmed <- confirmed[ ,ncol(confirmed)]
recent_deaths <- deaths[ ,ncol(deaths)]

#create new data frame with the first 4 columns of confirmed data frame
riskscores <- confirmed[, 1:4]

#add deaths column to data frame
riskscores$deaths <- recent_deaths

#add confirmed to data frame
riskscores$confirmed <- recent_confirmed

#calculating and adding risk scores to new data frame
riskscores$risk_score <- round((recent_deaths / recent_confirmed * 100), digits = 4)

#sort the data frame by
riskscores_sorted_ascend <- riskscores[order(riskscores$risk_score, -riskscores$confirmed), ]
#head(riskscores_sorted_ascend, 2)

riskscores_sorted_descend <- riskscores[order(-riskscores$risk_score, -riskscores$confirmed), ]
#head(riskscores_sorted_descend, 2)


```
Which area of the world currently has the lowest risk score(if more than one, display the one with the most confirmations)?
``` {r echo=FALSE}
head(riskscores_sorted_ascend, 2)
```
Which area of the world currently has the highest risk score (if more than one, display the one with the most confirmations)?
``` {r echo=FALSE}
head(riskscores_sorted_descend, 2)
```
How do risk scores in these areas compare to global risk score?
``` {r}
globalrisk <- sum(riskscores$deaths) / sum(riskscores$confirmed) * 100
print(paste(round(globalrisk, 4), "is the global risk score."))
```
The global risk score is close to one, which means we have decent care options for people confirmed to have COVID.  

Why might it be helpful to calculate metrics like risk scores for different areas of the world and what would their limitations be (what assumptions does risk score make and what important variables might be left out?)  
  
Looking at risk score over the entire globe seems like a bad idea to me. We are not looking at the economic status of countries which would definitely have a large impact on risk scores due to this leading to the quality of healthcare available. It also doesnt consider cultural norms like wearing a mask, I would expect to see lower risk scores in countries where wearing a mask was already a cultural norm. Risk score also is assuming that the data is correct, an easy outliar to see is North Korea, having a risk score of 600. with 0 confirmations 6 people died due to covid related issues...


>>>>>>> d8679cdad1eb5e764396c6a4d2d7603e877085b6
